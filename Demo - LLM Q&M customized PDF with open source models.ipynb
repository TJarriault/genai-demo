{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0f8b5d-4201-4a39-a5be-56c90e10d482",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Adapting LLM Q&A to our PDF data using LangChain through Open Source Models\n",
    "![src/genai.png](src/genai.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a98bf34-ff52-4e9b-ba60-cd134ac37b06",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initialize hugging face authentication using access token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d9d3a40-40be-40f5-8300-5b2faaeb94c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['HuggingFaceHub_API_Token']= 'mention_your_key_here'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe459e-8767-40c5-a710-aa03eca6cf9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Listing CV PDF Files\n",
    "\n",
    "In the code cell below, we list the tax filing instruction files stored locally in the 'docs/' directory using the `ls` command. This command is commonly used to display the contents of a directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5e10f3d-5c45-472c-8f3d-48bced3217a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 128K\n",
      "-rw-r--r-- 1 jupyter jupyter 74K Jan 27 16:54 'Profile Linkedin Laurent.pdf'\n",
      "-rw-r--r-- 1 jupyter jupyter 50K Jan  8 09:22 'Profile Linkedin Tony.pdf'\n"
     ]
    }
   ],
   "source": [
    "!ls -lh docs/\n",
    "text_folder = 'docs'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5e6911-97e3-4e15-af53-d966e81dad11",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Demo: Creating and Querying Vector Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608e309a-fd50-47a7-9d4a-e1e6316f5d62",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Create the Query\n",
    "We start by creating a query that includes the questions \"Who is Tony?\" and \"Who is Laurent?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d35f858-1a33-454a-a1c1-845b9396bbd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who is Tony?\\nWho is Laurent?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"Who is Tony?\n",
    "Who is Laurent?\"\"\"\n",
    "\n",
    "query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f43ffb9-eef3-4af9-9dcf-44ffefc13458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f43fe7a-3f66-4b5b-a189-396ad373b621",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2: Create Vector Store\n",
    "\n",
    "Next, we create a vector store using a subset of documents from the specified text folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae5095a-f568-4c78-8821-736888e1500c",
   "metadata": {
    "tags": []
   },
   "source": [
    "The following code snippet demonstrates the importation of key modules from the `langchain` library:\n",
    "\n",
    "- `UnstructuredPDFLoader`: Handles loading and parsing of unstructured PDF documents.\n",
    "- `CharacterTextSplitter`: Facilitates effective text splitting, breaking down textual data into characters.\n",
    "- `HuggingFaceEmbeddings`: Integrates Hugging Face's embeddings, enabling state-of-the-art language representations.\n",
    "- `FAISS`: Provides support for efficient storage and retrieval of document vectors through FAISS.\n",
    "- `torch`: Integrates with PyTorch, a powerful deep learning library, allowing advanced customization and compatibility with neural network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bf55c24-c946-4b73-ba88-a9d81a633037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e940198-5694-47e7-b992-5d64dbe82fd3",
   "metadata": {},
   "source": [
    "#### Get a list of all files in the specified directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "038709db-2c00-4118-8243-44331b270f66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Profile Linkedin Laurent.pdf', 'Profile Linkedin Tony.pdf']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = [f for f in os.listdir(text_folder) if os.path.isfile(os.path.join(text_folder, f))]\n",
    "all_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eff7761-e0c8-4cba-a2a5-d73d67978f25",
   "metadata": {},
   "source": [
    "#### Load documents from PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8552dd2-c6ff-4496-a596-2b51fd39921c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Contact\\n\\n+33698600201 (Mobile) laurent.grangeau@gmail.com\\n\\nwww.linkedin.com/in/ laurentgrangeau (LinkedIn) www.laurentgrangeau.fr (Personal)\\n\\nTop Skills\\n\\nPublic Cloud\\n\\nIndependence\\n\\nDevOps\\n\\nLanguages\\n\\nFrancais (Native or Bilingual)\\n\\nAnglais (Native or Bilingual)\\n\\nEspagnol (Elementary)\\n\\nCertifications\\n\\nMCP 70-536 - TS: Microsoft .NET Framework - Application Development Foundation\\n\\nCertification Architecte SI\\n\\nMCTS 70-562 - TS: Microsoft .NET Framework 3.5, ASP.NET Application Development\\n\\nM101P, MongoDB for Developers\\n\\nMCTS 70-516 - TS: Accessing Data with Microsoft .NET Framework 4\\n\\nHonors-Awards\\n\\nFinaliste Hackathon DSI\\n\\nMicrosoft MVP Azure - 2018\\n\\nLaurent Grangeau\\n\\nSolutions Architect at Google Paris et périphérie\\n\\nSummary\\n\\nJ'accompagne nos clients dans leur transformation numérique. Je\\n\\nles aide à gagner en productivité, réduire leur time-to-market, ainsi\\n\\nque leur coût d'infrastructure en développant leur stratégie cloud\\n\\nExperience\\n\\nGoogle Solutions Architect November 2021 - Present (2 years 3 months) Paris, Île-de-France, France\\n\\nCodeForCloud Founder - CEO October 2018 - Present (5 years 4 months)\\n\\nFormateur Udemy\\n\\nConférencier Cloud / DevOps ECE Paris.Lyon\\n\\nConférencier Cloud / DevOps Junia\\n\\nConférencier Cloud / DevOps Sup'galilée\\n\\nConférencier Cloud / DevOps IUT Montreuil\\n\\nRockchain Cloud advisor February 2017 - Present (7 years) Région de Paris, France\\n\\nRockchain: solving privacy on the blockchain. Rockchain is a distributed\\n\\nnetwork working along Ethereum to extend the public blockchain on private\\n\\ndatastores. It can perform public computation on private data.\\n\\nParis Serverless Architecture Meetup Organizer September 2016 - Present (7 years 5 months)\\n\\nAll Day DevOps partner\\n\\nMeta meetup DevOps & Craftsmanship : Présentation du framework\\n\\nOpenWhisk\\n\\nPage 1 of 5\\n\\nMeetup #6 : APIs dans Azure, serverless ou pas serverless ?\\n\\nMeetup #5 : Google Functions\\n\\nMeetup #4 : Gojko Adzic et Yan Cui à la NewCrafts conférence\\n\\nMeetup #3 : Avantages / Cas d'usage du Serverless - Le projet opensource\\n\\nOpenWhisk\\n\\nMeetup #2 : Serverless frameworks on AWS\\n\\nMeetup #1 : Azure Functions, exécution de nano-services en mode serverless\\n\\nSpeaker Speaker February 2013 - Present (11 years)\\n\\n2017 : Skynet vs Planet of the Apes - DockerCon EU\\n\\n2017 : Skynet vs Planet of the Apes - Breizhcamp\\n\\n2017 : Skynet vs Planet of the Apes - Voxxed day Luxembourg\\n\\n2017 : Skynet vs Planet of the Apes - Devoxx\\n\\n2017 : All you need is orchestration ! - Snowcamp.io\\n\\n2016 : Containers orchestration : an overview of Swarm, Mesos, Kubernetes\\n\\nand Nomad - API Days\\n\\n2016 : Globak Mentor Week - Meetup Docker\\n\\n2016 : Making a mammoth run : continuous delivery in a bank - DevOpsDDay\\n\\n2016 : Docker Windows + Continuous Delivery = <3 - Microsoft Experiences\\n\\n2016 : Docker Windows + Continuous Delivery = <3 - Meetup Docker\\n\\n2016 : Making a mammoth run : continuous delivery in a bank - HashiConf EU\\n\\n2015 : The missing piece : when Docker networking unleashes software\\n\\narchitecture 2.0 - DockerCon EU\\n\\n2015 : Networking with Docker - Pioneers.io\\n\\n2013 : BI analysis with SQL Server 2012 - Microsoft TechDays\\n\\nSogeti 4 years 6 months\\n\\nTechnical Partner Manager January 2021 - November 2021 (11 months) Paris et périphérie\\n\\nCloud Solution Architect | Business Developer June 2017 - January 2021 (3 years 8 months) Issy les moulineaux\\n\\nSogetiLabs fellow : http://labs.sogeti.com/experts/laurent-grangeau/\\n\\nMember of CapGemini Expert Connect program : https://www.capgemini.com/\\n\\nexperts/cloud-services/laurent-grangeau/\\n\\nPage 2 of 5\\n\\nFINAXYS 2 years 5 months\\n\\nCloud solution Architect | Consultant manager January 2017 - June 2017 (6 months)\\n\\nMigration du SI de Kepler Cheuvreux vers le cloud AWS : Chiffrage du TCO,\\n\\nDéfinition de leur nouvelle architecture, Mise en place de best practices.\\n\\nResponsable de l'offre Cloud : Participation aux avant-ventes, Définition de\\n\\nl'architecture Cloud de nos clients.\\n\\nConsultant Manager - DevOps coach February 2015 - December 2016 (1 year 11 months) La Défense\\n\\nTransformation d'applications vers des pratiques Continuous Delivery afin\\n\\nde réduire le TTM et le TTD : Accompagnement des équipes aux pratiques\\n\\nDevOps, Mise en place d'une usine logicielle implémentant le Continuous\\n\\nDelivery, Mise en place de l'automatisation des déploiements.\\n\\nParticipation au programme Cloud & PaaS dans la cellule d'architecture\\n\\ntransverse : Définition de la plateforme Docker, Formation des utilisateurs à\\n\\nDocker, Accompagnement des applications dans leur transformation, Mise en\\n\\nplace d'outils afin de résoudre les nouvelles problématiques de scalabilité et\\n\\nde résilience, Responsable de la sécurité des applications.\\n\\nBouygues Telecom 5 years 11 months\\n\\nArchitecte logiciel March 2013 - January 2015 (1 year 11 months)\\n\\nResponsable de la qualité logiciel et des normes de développement dans une\\n\\néquipe de 50 personnes gérant 80 systèmes techniques\\n\\nInstallation et migration vers Team Foundation Server 2013\\n\\nMigration vers SQL Server 2012\\n\\nDéveloppement de solutions dans le cloud\\n\\nMise en place d'une démarche DevOps\\n\\nCréation et animation de réunion autour des technologies Microsoft au sein\\n\\ndu groupe Bouygues\\n\\nResponsable sécurité\\n\\nDéveloppement d'une application Web ASP.NET MVC 5 multi-langue\\n\\nVeille technologique\\n\\nDéveloppement d'une plateforme collaborative multi-constructeur mobile\\n\\nBudget : 150k\\n\\nGain : productivité accrue\\n\\nPage 3 of 5\\n\\nArchitecte logiciel - Chef de projet September 2010 - March 2013 (2 years 7 months) Région de Paris , France\\n\\nDévelopper des solutions transverse pour augmenter la productivité des\\n\\néquipes de développement\\n\\nInstallation et configuration de Jenkins pour les projets de l'équipe de\\n\\ndéveloppement\\n\\nInstallation et configuration de Sonar pour les projets de l'équipe de\\n\\ndéveloppement\\n\\nRédaction des normes de développement\\n\\nAudit de code\\n\\nCréation et animation des OpenDev (principe des Brown Bag Lunch)\\n\\nMigration vers Team Foundation Server 2010\\n\\nMise en place d'un process de gestion de projet agile avec Team Foundation\\n\\nServer\\n\\nCotateur IFPug\\n\\nMise en place de l'architecture des différents projets de l'équipe\\n\\nSpeaker au Techdays 2013\\n\\nIngénieur .NET - Chef de projet March 2010 - September 2010 (7 months) Région de Paris , France\\n\\nGestion des projets FAI des clients entreprises\\n\\nIngénieur développement .NET March 2009 - March 2010 (1 year 1 month) Région de Paris , France\\n\\nDéveloppement de projets en mode agile\\n\\nSellermania Ingénieur développement JavaEE January 2008 - March 2009 (1 year 3 months) Région de Paris , France\\n\\nDévelopper une solution de mise en vente multi-marketplace\\n\\nAtos Origin Ingénieur dévelopement J2EE September 2006 - January 2008 (1 year 5 months) Région de Paris , France\\n\\nDans une équipe au sein de la CNAM/TS, j'ai eu deux principales missions\\n\\nconsistant pour la première à la définition des normes et standards de\\n\\nPage 4 of 5\\n\\ndéveloppement Java de la CNAM/TS ; et pour la seconde au développement\\n\\nde la plateforme d'accès aux statistiques des assurés de la CNAM/TS.\\n\\nLes gains constatés sur ces deux missions fut pour la première le déploiement\\n\\nde normes et standards utilisés par tous les développeurs de la CNAM/TS ;\\n\\net pour la seconde la réussite complète de la migration d'une plateforme\\n\\nBusiness Objects vers une plateforme Oracle Application Server.\\n\\nEducation\\n\\n3IL - Institut d'ingénierie informatique de Limoges\\n\\nDiplome d'ingénieur en informatique, Option Réseaux et\\n\\nSécurité · (2003 - 2006)\\n\\nIUT GEII Mont Saint Aignan\\n\\nDUT Génie Electrique et Informatique Industrielle, Option Réseaux\\n\\nIndustriels · (2001 - 2003)\\n\\nPage 5 of 5\", metadata={'source': 'docs/Profile Linkedin Laurent.pdf'}),\n",
       " Document(page_content=\"Contact\\n\\n0134490643 (Work) tjarriault@free.fr\\n\\nwww.linkedin.com/in/tonyjarriault (LinkedIn)\\n\\nTop Skills\\n\\nSecurity\\n\\nITIL\\n\\nLinux\\n\\nLanguages\\n\\nEnglish\\n\\nCertifications\\n\\nHashiCorp Certified: Vault Associate\\n\\nHashicorp terraform\\n\\nProfessional Cloud Security Engineer\\n\\nJarriault Tony\\n\\nSolutions Architect @Sogeti part of CapGemini Greater Toulouse Metropolitan Area\\n\\nSummary\\n\\n☁ Cloud solution architect with a passion for new technologies. I\\n\\nhave been immersed in the cloud for over 10 years :)\\n\\n☑️I also have significant experience in infrastructure and onprem\\n\\napplications\\n\\n☑️TechLead GCP, I help teams and customers in the adoption of\\n\\nthe cloud to help them pursue an exciting adventure around topics\\n\\nsuch as: Finops / DevSecops / Micro-Service ...\\n\\nSpeaker on public event, i share my passion about cloud technology\\n\\nFavourite topics : ️AWS / ️GCP / ️Finops / ️DevSecOps / ️Cloud\\n\\nExperience\\n\\nSogeti Cloud Solutions Architect January 2019 - Present (5 years) Toulouse Area, France\\n\\nPROSODIE 23 years 11 months\\n\\nResponsable suivi mise en service February 2000 - Present (23 years 11 months)\\n\\n️ Mise en place d’une politique de suivi des incidents et problèmes pour\\n\\ncontribuer au respect des SLA souscris.\\n\\n️ Suivi quotidien de l’évolution des incidents relatif à l’équipe\\n\\n️ Étude et mise en œuvre de plans d’action relatifs aux incidents\\n\\n️ Traitements des problèmes quotidiennement pour la stabilisation à long\\n\\nterme\\n\\n️ Suivi technique des des projets\\n\\n️ Suivi au bon respect de nos engagements planification / déploiement\\n\\nPage 1 of 2\\n\\n️ Standardisation et industrialisation de nos process pour l’ensemble des\\n\\ntechnologies déployées.\\n\\n️ Mise en service d’architectures de communications unifiées (LYNC) + VOIP.\\n\\n️ Standardisation du processus de déploiement pour les technologies\\n\\nMiddleware les plus fréquemment rencontrées (Exemple : Sharepoint 2013,\\n\\nsolution CMS open Source) + OS\\n\\n️ Suivi des phases d'avant vente pour aide la définition d'architecture.\\n\\nReponsable de groupe Mise en service (Technique) July 2012 - January 2019 (6 years 7 months) Velizy\\n\\nRepsonsable du suivi en phase de mise en service des projets (aspect\\n\\ntechnique)\\n\\nCoordination des ressources de l'équipe pour fluidifier les mises en service.\\n\\nOdigo Manager Gestionnaire applicatif outsource. -- Architecte Cloud November 2014 - January 2019 (4 years 3 months) Velizy villacoublay\\n\\nManager technique et applicatif (exploitation) d'équipes niveau 1- équipe\\n\\nonshore/offshore\\n\\nArchitecte : externalisation SI dans diverses solutions Cloud (AWS / OVH)\\n\\nAtos Origin/Prosodie Resp MES 2009 - 2010 (1 year)\\n\\nEducation\\n\\nSKEMA Business School\\n\\n(1976)\\n\\nIUT d'informatique de Toulouse\\n\\n3\\n\\nPage 2 of 2\", metadata={'source': 'docs/Profile Linkedin Tony.pdf'})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = []\n",
    "for file in all_files:\n",
    "    loader = UnstructuredPDFLoader(os.path.join(text_folder, file))\n",
    "    documents.extend(loader.load())\n",
    "    \n",
    "documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7168976c-1240-4bd3-a735-bfb40a0f8fbc",
   "metadata": {},
   "source": [
    "#### Split documents into text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "459a5f5c-fe68-4584-9873-485e95d9ceea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Contact\\n+33698600201 (Mobile) laurent.grangeau@gmail.com\\nwww.linkedin.com/in/ laurentgrangeau (LinkedIn) www.laurentgrangeau.fr (Personal)\\nTop Skills\\nPublic Cloud\\nIndependence\\nDevOps\\nLanguages\\nFrancais (Native or Bilingual)\\nAnglais (Native or Bilingual)\\nEspagnol (Elementary)\\nCertifications\\nMCP 70-536 - TS: Microsoft .NET Framework - Application Development Foundation\\nCertification Architecte SI\\nMCTS 70-562 - TS: Microsoft .NET Framework 3.5, ASP.NET Application Development\\nM101P, MongoDB for Developers\\nMCTS 70-516 - TS: Accessing Data with Microsoft .NET Framework 4\\nHonors-Awards\\nFinaliste Hackathon DSI\\nMicrosoft MVP Azure - 2018\\nLaurent Grangeau\\nSolutions Architect at Google Paris et périphérie\\nSummary\\nJ'accompagne nos clients dans leur transformation numérique. Je\\nles aide à gagner en productivité, réduire leur time-to-market, ainsi\\nque leur coût d'infrastructure en développant leur stratégie cloud\\nExperience\", metadata={'source': 'docs/Profile Linkedin Laurent.pdf'}),\n",
       " Document(page_content=\"Experience\\nGoogle Solutions Architect November 2021 - Present (2 years 3 months) Paris, Île-de-France, France\\nCodeForCloud Founder - CEO October 2018 - Present (5 years 4 months)\\nFormateur Udemy\\nConférencier Cloud / DevOps ECE Paris.Lyon\\nConférencier Cloud / DevOps Junia\\nConférencier Cloud / DevOps Sup'galilée\\nConférencier Cloud / DevOps IUT Montreuil\\nRockchain Cloud advisor February 2017 - Present (7 years) Région de Paris, France\\nRockchain: solving privacy on the blockchain. Rockchain is a distributed\\nnetwork working along Ethereum to extend the public blockchain on private\\ndatastores. It can perform public computation on private data.\\nParis Serverless Architecture Meetup Organizer September 2016 - Present (7 years 5 months)\\nAll Day DevOps partner\\nMeta meetup DevOps & Craftsmanship : Présentation du framework\\nOpenWhisk\\nPage 1 of 5\\nMeetup #6 : APIs dans Azure, serverless ou pas serverless ?\\nMeetup #5 : Google Functions\\nMeetup #4 : Gojko Adzic et Yan Cui à la NewCrafts conférence\", metadata={'source': 'docs/Profile Linkedin Laurent.pdf'}),\n",
       " Document(page_content=\"Meetup #3 : Avantages / Cas d'usage du Serverless - Le projet opensource\\nOpenWhisk\\nMeetup #2 : Serverless frameworks on AWS\\nMeetup #1 : Azure Functions, exécution de nano-services en mode serverless\\nSpeaker Speaker February 2013 - Present (11 years)\\n2017 : Skynet vs Planet of the Apes - DockerCon EU\\n2017 : Skynet vs Planet of the Apes - Breizhcamp\\n2017 : Skynet vs Planet of the Apes - Voxxed day Luxembourg\\n2017 : Skynet vs Planet of the Apes - Devoxx\\n2017 : All you need is orchestration ! - Snowcamp.io\\n2016 : Containers orchestration : an overview of Swarm, Mesos, Kubernetes\\nand Nomad - API Days\\n2016 : Globak Mentor Week - Meetup Docker\\n2016 : Making a mammoth run : continuous delivery in a bank - DevOpsDDay\\n2016 : Docker Windows + Continuous Delivery = <3 - Microsoft Experiences\\n2016 : Docker Windows + Continuous Delivery = <3 - Meetup Docker\\n2016 : Making a mammoth run : continuous delivery in a bank - HashiConf EU\\n2015 : The missing piece : when Docker networking unleashes software\", metadata={'source': 'docs/Profile Linkedin Laurent.pdf'}),\n",
       " Document(page_content=\"architecture 2.0 - DockerCon EU\\n2015 : Networking with Docker - Pioneers.io\\n2013 : BI analysis with SQL Server 2012 - Microsoft TechDays\\nSogeti 4 years 6 months\\nTechnical Partner Manager January 2021 - November 2021 (11 months) Paris et périphérie\\nCloud Solution Architect | Business Developer June 2017 - January 2021 (3 years 8 months) Issy les moulineaux\\nSogetiLabs fellow : http://labs.sogeti.com/experts/laurent-grangeau/\\nMember of CapGemini Expert Connect program : https://www.capgemini.com/\\nexperts/cloud-services/laurent-grangeau/\\nPage 2 of 5\\nFINAXYS 2 years 5 months\\nCloud solution Architect | Consultant manager January 2017 - June 2017 (6 months)\\nMigration du SI de Kepler Cheuvreux vers le cloud AWS : Chiffrage du TCO,\\nDéfinition de leur nouvelle architecture, Mise en place de best practices.\\nResponsable de l'offre Cloud : Participation aux avant-ventes, Définition de\\nl'architecture Cloud de nos clients.\", metadata={'source': 'docs/Profile Linkedin Laurent.pdf'}),\n",
       " Document(page_content=\"l'architecture Cloud de nos clients.\\nConsultant Manager - DevOps coach February 2015 - December 2016 (1 year 11 months) La Défense\\nTransformation d'applications vers des pratiques Continuous Delivery afin\\nde réduire le TTM et le TTD : Accompagnement des équipes aux pratiques\\nDevOps, Mise en place d'une usine logicielle implémentant le Continuous\\nDelivery, Mise en place de l'automatisation des déploiements.\\nParticipation au programme Cloud & PaaS dans la cellule d'architecture\\ntransverse : Définition de la plateforme Docker, Formation des utilisateurs à\\nDocker, Accompagnement des applications dans leur transformation, Mise en\\nplace d'outils afin de résoudre les nouvelles problématiques de scalabilité et\\nde résilience, Responsable de la sécurité des applications.\\nBouygues Telecom 5 years 11 months\\nArchitecte logiciel March 2013 - January 2015 (1 year 11 months)\\nResponsable de la qualité logiciel et des normes de développement dans une\\néquipe de 50 personnes gérant 80 systèmes techniques\", metadata={'source': 'docs/Profile Linkedin Laurent.pdf'}),\n",
       " Document(page_content=\"Installation et migration vers Team Foundation Server 2013\\nMigration vers SQL Server 2012\\nDéveloppement de solutions dans le cloud\\nMise en place d'une démarche DevOps\\nCréation et animation de réunion autour des technologies Microsoft au sein\\ndu groupe Bouygues\\nResponsable sécurité\\nDéveloppement d'une application Web ASP.NET MVC 5 multi-langue\\nVeille technologique\\nDéveloppement d'une plateforme collaborative multi-constructeur mobile\\nBudget : 150k\\nGain : productivité accrue\\nPage 3 of 5\\nArchitecte logiciel - Chef de projet September 2010 - March 2013 (2 years 7 months) Région de Paris , France\\nDévelopper des solutions transverse pour augmenter la productivité des\\néquipes de développement\\nInstallation et configuration de Jenkins pour les projets de l'équipe de\\ndéveloppement\\nInstallation et configuration de Sonar pour les projets de l'équipe de\\ndéveloppement\\nRédaction des normes de développement\\nAudit de code\\nCréation et animation des OpenDev (principe des Brown Bag Lunch)\", metadata={'source': 'docs/Profile Linkedin Laurent.pdf'}),\n",
       " Document(page_content=\"Migration vers Team Foundation Server 2010\\nMise en place d'un process de gestion de projet agile avec Team Foundation\\nServer\\nCotateur IFPug\\nMise en place de l'architecture des différents projets de l'équipe\\nSpeaker au Techdays 2013\\nIngénieur .NET - Chef de projet March 2010 - September 2010 (7 months) Région de Paris , France\\nGestion des projets FAI des clients entreprises\\nIngénieur développement .NET March 2009 - March 2010 (1 year 1 month) Région de Paris , France\\nDéveloppement de projets en mode agile\\nSellermania Ingénieur développement JavaEE January 2008 - March 2009 (1 year 3 months) Région de Paris , France\\nDévelopper une solution de mise en vente multi-marketplace\\nAtos Origin Ingénieur dévelopement J2EE September 2006 - January 2008 (1 year 5 months) Région de Paris , France\\nDans une équipe au sein de la CNAM/TS, j'ai eu deux principales missions\\nconsistant pour la première à la définition des normes et standards de\\nPage 4 of 5\", metadata={'source': 'docs/Profile Linkedin Laurent.pdf'}),\n",
       " Document(page_content=\"Page 4 of 5\\ndéveloppement Java de la CNAM/TS ; et pour la seconde au développement\\nde la plateforme d'accès aux statistiques des assurés de la CNAM/TS.\\nLes gains constatés sur ces deux missions fut pour la première le déploiement\\nde normes et standards utilisés par tous les développeurs de la CNAM/TS ;\\net pour la seconde la réussite complète de la migration d'une plateforme\\nBusiness Objects vers une plateforme Oracle Application Server.\\nEducation\\n3IL - Institut d'ingénierie informatique de Limoges\\nDiplome d'ingénieur en informatique, Option Réseaux et\\nSécurité · (2003 - 2006)\\nIUT GEII Mont Saint Aignan\\nDUT Génie Electrique et Informatique Industrielle, Option Réseaux\\nIndustriels · (2001 - 2003)\\nPage 5 of 5\", metadata={'source': 'docs/Profile Linkedin Laurent.pdf'}),\n",
       " Document(page_content='Contact\\n0134490643 (Work) tjarriault@free.fr\\nwww.linkedin.com/in/tonyjarriault (LinkedIn)\\nTop Skills\\nSecurity\\nITIL\\nLinux\\nLanguages\\nEnglish\\nCertifications\\nHashiCorp Certified: Vault Associate\\nHashicorp terraform\\nProfessional Cloud Security Engineer\\nJarriault Tony\\nSolutions Architect @Sogeti part of CapGemini Greater Toulouse Metropolitan Area\\nSummary\\n☁ Cloud solution architect with a passion for new technologies. I\\nhave been immersed in the cloud for over 10 years :)\\n☑️I also have significant experience in infrastructure and onprem\\napplications\\n☑️TechLead GCP, I help teams and customers in the adoption of\\nthe cloud to help them pursue an exciting adventure around topics\\nsuch as: Finops / DevSecops / Micro-Service ...\\nSpeaker on public event, i share my passion about cloud technology\\nFavourite topics : ️AWS / ️GCP / ️Finops / ️DevSecOps / ️Cloud\\nExperience\\nSogeti Cloud Solutions Architect January 2019 - Present (5 years) Toulouse Area, France\\nPROSODIE 23 years 11 months', metadata={'source': 'docs/Profile Linkedin Tony.pdf'}),\n",
       " Document(page_content=\"PROSODIE 23 years 11 months\\nResponsable suivi mise en service February 2000 - Present (23 years 11 months)\\n️ Mise en place d’une politique de suivi des incidents et problèmes pour\\ncontribuer au respect des SLA souscris.\\n️ Suivi quotidien de l’évolution des incidents relatif à l’équipe\\n️ Étude et mise en œuvre de plans d’action relatifs aux incidents\\n️ Traitements des problèmes quotidiennement pour la stabilisation à long\\nterme\\n️ Suivi technique des des projets\\n️ Suivi au bon respect de nos engagements planification / déploiement\\nPage 1 of 2\\n️ Standardisation et industrialisation de nos process pour l’ensemble des\\ntechnologies déployées.\\n️ Mise en service d’architectures de communications unifiées (LYNC) + VOIP.\\n️ Standardisation du processus de déploiement pour les technologies\\nMiddleware les plus fréquemment rencontrées (Exemple : Sharepoint 2013,\\nsolution CMS open Source) + OS\\n️ Suivi des phases d'avant vente pour aide la définition d'architecture.\", metadata={'source': 'docs/Profile Linkedin Tony.pdf'}),\n",
       " Document(page_content=\"Reponsable de groupe Mise en service (Technique) July 2012 - January 2019 (6 years 7 months) Velizy\\nRepsonsable du suivi en phase de mise en service des projets (aspect\\ntechnique)\\nCoordination des ressources de l'équipe pour fluidifier les mises en service.\\nOdigo Manager Gestionnaire applicatif outsource. -- Architecte Cloud November 2014 - January 2019 (4 years 3 months) Velizy villacoublay\\nManager technique et applicatif (exploitation) d'équipes niveau 1- équipe\\nonshore/offshore\\nArchitecte : externalisation SI dans diverses solutions Cloud (AWS / OVH)\\nAtos Origin/Prosodie Resp MES 2009 - 2010 (1 year)\\nEducation\\nSKEMA Business School\\n(1976)\\nIUT d'informatique de Toulouse\\n3\\nPage 2 of 2\", metadata={'source': 'docs/Profile Linkedin Tony.pdf'})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(separator='\\n', chunk_size=1000, chunk_overlap=50)\n",
    "text_chunks = text_splitter.split_documents(documents)\n",
    "text_chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cacd07b-05c3-4950-83ab-ae6711a9c978",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Set the Hugging Face model name and model arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "115bc150-a728-4db3-b244-69513b2cc2e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentence-transformers/all-MiniLM-L6-v2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "model_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4667d97-c171-4c05-8e33-176aba71ff5c",
   "metadata": {},
   "source": [
    "##### Check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b3f0aa0-4e83-4e79-b512-2aa3af158d61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc2e481c-d9b6-4605-91d2-81bc81e23df4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': 'cuda'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kwargs = {'device': device.type}\n",
    "model_kwargs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea899f5-4797-4d43-b0ce-12dfabdc1449",
   "metadata": {},
   "source": [
    "#### Initialize Hugging Face embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2894ce04-03ba-49b0-bc9f-0bd55f88110c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={'device': 'cuda'}, encode_kwargs={}, multi_process=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
    "embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c853a6cf-885b-42f8-81f3-d62082cbef84",
   "metadata": {},
   "source": [
    "#### Create a vector store using FAISS from the text chunks and embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97706a18-6ca8-4455-a1eb-cfcc290ce2cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x7f3a82eff760>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore=FAISS.from_documents(text_chunks, embeddings)\n",
    "vectorstore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef499af7-d1b8-4b45-b451-9c030a10b4f2",
   "metadata": {},
   "source": [
    "#### Query the vectore store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfe6a6be-b880-4176-b43f-0c4be39e60a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Contact\\n+33698600201 (Mobile) laurent.grangeau@gmail.com\\nwww.linkedin.com/in/ laurentgrangeau (LinkedIn) www.laurentgrangeau.fr (Personal)\\nTop Skills\\nPublic Cloud\\nIndependence\\nDevOps\\nLanguages\\nFrancais (Native or Bilingual)\\nAnglais (Native or Bilingual)\\nEspagnol (Elementary)\\nCertifications\\nMCP 70-536 - TS: Microsoft .NET Framework - Application Development Foundation\\nCertification Architecte SI\\nMCTS 70-562 - TS: Microsoft .NET Framework 3.5, ASP.NET Application Development\\nM101P, MongoDB for Developers\\nMCTS 70-516 - TS: Accessing Data with Microsoft .NET Framework 4\\nHonors-Awards\\nFinaliste Hackathon DSI\\nMicrosoft MVP Azure - 2018\\nLaurent Grangeau\\nSolutions Architect at Google Paris et périphérie\\nSummary\\nJ'accompagne nos clients dans leur transformation numérique. Je\\nles aide à gagner en productivité, réduire leur time-to-market, ainsi\\nque leur coût d'infrastructure en développant leur stratégie cloud\\nExperience\", metadata={'source': 'docs/Profile Linkedin Laurent.pdf'}),\n",
       " Document(page_content='Contact\\n0134490643 (Work) tjarriault@free.fr\\nwww.linkedin.com/in/tonyjarriault (LinkedIn)\\nTop Skills\\nSecurity\\nITIL\\nLinux\\nLanguages\\nEnglish\\nCertifications\\nHashiCorp Certified: Vault Associate\\nHashicorp terraform\\nProfessional Cloud Security Engineer\\nJarriault Tony\\nSolutions Architect @Sogeti part of CapGemini Greater Toulouse Metropolitan Area\\nSummary\\n☁ Cloud solution architect with a passion for new technologies. I\\nhave been immersed in the cloud for over 10 years :)\\n☑️I also have significant experience in infrastructure and onprem\\napplications\\n☑️TechLead GCP, I help teams and customers in the adoption of\\nthe cloud to help them pursue an exciting adventure around topics\\nsuch as: Finops / DevSecops / Micro-Service ...\\nSpeaker on public event, i share my passion about cloud technology\\nFavourite topics : ️AWS / ️GCP / ️Finops / ️DevSecOps / ️Cloud\\nExperience\\nSogeti Cloud Solutions Architect January 2019 - Present (5 years) Toulouse Area, France\\nPROSODIE 23 years 11 months', metadata={'source': 'docs/Profile Linkedin Tony.pdf'}),\n",
       " Document(page_content=\"Meetup #3 : Avantages / Cas d'usage du Serverless - Le projet opensource\\nOpenWhisk\\nMeetup #2 : Serverless frameworks on AWS\\nMeetup #1 : Azure Functions, exécution de nano-services en mode serverless\\nSpeaker Speaker February 2013 - Present (11 years)\\n2017 : Skynet vs Planet of the Apes - DockerCon EU\\n2017 : Skynet vs Planet of the Apes - Breizhcamp\\n2017 : Skynet vs Planet of the Apes - Voxxed day Luxembourg\\n2017 : Skynet vs Planet of the Apes - Devoxx\\n2017 : All you need is orchestration ! - Snowcamp.io\\n2016 : Containers orchestration : an overview of Swarm, Mesos, Kubernetes\\nand Nomad - API Days\\n2016 : Globak Mentor Week - Meetup Docker\\n2016 : Making a mammoth run : continuous delivery in a bank - DevOpsDDay\\n2016 : Docker Windows + Continuous Delivery = <3 - Microsoft Experiences\\n2016 : Docker Windows + Continuous Delivery = <3 - Meetup Docker\\n2016 : Making a mammoth run : continuous delivery in a bank - HashiConf EU\\n2015 : The missing piece : when Docker networking unleashes software\", metadata={'source': 'docs/Profile Linkedin Laurent.pdf'}),\n",
       " Document(page_content=\"architecture 2.0 - DockerCon EU\\n2015 : Networking with Docker - Pioneers.io\\n2013 : BI analysis with SQL Server 2012 - Microsoft TechDays\\nSogeti 4 years 6 months\\nTechnical Partner Manager January 2021 - November 2021 (11 months) Paris et périphérie\\nCloud Solution Architect | Business Developer June 2017 - January 2021 (3 years 8 months) Issy les moulineaux\\nSogetiLabs fellow : http://labs.sogeti.com/experts/laurent-grangeau/\\nMember of CapGemini Expert Connect program : https://www.capgemini.com/\\nexperts/cloud-services/laurent-grangeau/\\nPage 2 of 5\\nFINAXYS 2 years 5 months\\nCloud solution Architect | Consultant manager January 2017 - June 2017 (6 months)\\nMigration du SI de Kepler Cheuvreux vers le cloud AWS : Chiffrage du TCO,\\nDéfinition de leur nouvelle architecture, Mise en place de best practices.\\nResponsable de l'offre Cloud : Participation aux avant-ventes, Définition de\\nl'architecture Cloud de nos clients.\", metadata={'source': 'docs/Profile Linkedin Laurent.pdf'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07113975-5485-4a0e-a783-a1965e9780f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3: Create the LLM model \n",
    "#### Convertational model\n",
    "\n",
    "Next, we create call the LLM model and put in heart the created vectore store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6d80e5-9870-4180-a982-fa1e776df607",
   "metadata": {},
   "source": [
    "The following code snippet showcases the importation of modules from the `transformers` library and specific modules from the `langchain` library:\n",
    "\n",
    "- `AutoTokenizer` and `AutoModelForCausalLM`: Imported from transformers for handling `tokenization` and causal language modeling.\n",
    "- `pipeline`: Another module from `transformers` for simplified access to a variety of NLP tasks.\n",
    "- `HuggingFacePipeline`: A module from `langchain` that likely provides additional functionalities or customization options when working with Hugging Face's transformers.\n",
    "- `RetrievalQA`: Imported from `langchain.chains` for implementing a question-answering component within the LangChain framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a393eb34-10b4-49ee-aea5-2cda8e021774",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8eccbd-9654-416d-9b03-45cc5c3da75c",
   "metadata": {},
   "source": [
    "### Setting Language Model Name\n",
    "\n",
    "In the code snippet below, the variable `llm_model_name` is assigned the value `'TinyLlama/TinyLlama-1.1B-Chat-v1.0'`. This represents the name or identifier of a specific language model, likely used in the context of natural language processing tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a544ea95-2c20-4544-afea-9706f934854a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_model_name = 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f310a38-790e-482b-aa6e-9f24b4d991b4",
   "metadata": {},
   "source": [
    "##### Initializing Tokenizer from Pretrained Model\n",
    "\n",
    "The following code initializes a tokenizer using the `AutoTokenizer.from_pretrained` method, specifying the pretrained language model named by the variable `llm_model_name`. The resulting `tokenizer` object is then displayed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7953af49-7054-4218-b783-94e139f29582",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='TinyLlama/TinyLlama-1.1B-Chat-v1.0', vocab_size=32000, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
    "tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24535b6e-fe12-4d6f-ad98-97f41d6c8bf0",
   "metadata": {},
   "source": [
    "##### Initializing Causal Language Model from Pretrained Model\n",
    "\n",
    "In the following code, a causal language model is initialized using the `AutoModelForCausalLM.from_pretrained` method. The pretrained language model specified by the variable `llm_model_name` is loaded onto the device automatically (`device_map='auto'`), and the model's tensor data type is set to `torch.float16`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03ff45d5-3095-43f7-9530-fbc22e53ba0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-21): 22 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(llm_model_name,\n",
    "                                             device_map='auto',\n",
    "                                             torch_dtype=torch.float16\n",
    "                                             )\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34375d1d-70c2-453c-80f3-044aa899bcb2",
   "metadata": {},
   "source": [
    "##### Creating Text Generation Pipeline\n",
    "\n",
    "The code snippet below demonstrates the creation of a text generation pipeline using the `pipeline` function from the `transformers` library. Various parameters are set for the pipeline, including the pretrained language model (`model`), tokenizer (`tokenizer`), tensor data type (`torch.bfloat16`), device allocation (`device_map='auto'`), maximum number of generated tokens (`max_new_tokens`), and other generation-related parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bedb96cf-6914-46e6-834d-9491b467286e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_generation.TextGenerationPipeline at 0x7f3a69c28c40>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\",\n",
    "                model=model,\n",
    "                tokenizer= tokenizer,\n",
    "                torch_dtype=torch.bfloat16,\n",
    "                device_map=\"auto\",\n",
    "                max_new_tokens = 1024,\n",
    "                do_sample=True,\n",
    "                top_k=10,\n",
    "                num_return_sequences=1,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "pipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d2d8dc-24a2-4daf-a8e8-4337a16d1573",
   "metadata": {},
   "source": [
    "##### Creating Hugging Face Pipeline with LangChain\n",
    "\n",
    "\n",
    "In the code snippet below, a LangChain pipeline (`HuggingFacePipeline`) is created, utilizing the previously defined text generation pipeline (`pipe`). Additional model-specific arguments are provided, setting the temperature to 0 for the language model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4d6e108-c3c1-45a2-b066-cf9c44f7b796",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7f3a69c28c40>, model_kwargs={'temperature': 0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = HuggingFacePipeline(pipeline=pipe, model_kwargs={'temperature':0})\n",
    "llm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdc1fbe-6db3-4735-8ca5-c99242354dda",
   "metadata": {},
   "source": [
    "##### Creating Retrieval Question-Answering Chain\n",
    "\n",
    "The following code snippet demonstrates the creation of a Retrieval Question-Answering chain (`chain`) using the LangChain module. The chain is initialized with the following components:\n",
    "\n",
    "- `llm`: The Hugging Face pipeline for text generation, configured earlier.\n",
    "- `chain_type`: A specific chain type, denoted as \"stuff.\"\n",
    "- `return_source_documents`: Set to `True` to include the source documents in the returned output.\n",
    "- `retriever`: The retriever component is defined as a vector store converted to a retriever using `vectorstore.as_retriever()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "697da2aa-05a1-4d06-a975-5f5c72fda922",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrievalQA(combine_documents_chain=StuffDocumentsChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7f3a69c28c40>, model_kwargs={'temperature': 0})), document_variable_name='context'), return_source_documents=True, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7f3a82eff760>))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain =  RetrievalQA.from_chain_type(\n",
    "    llm=llm # -> 'TinyLlama/TinyLlama-1.1B-Chat-v1.0' [Traitement de requete] -> Traitement automatique de langage naturel\n",
    "    , chain_type=\"stuff\"\n",
    "    , return_source_documents=True\n",
    "    , retriever=vectorstore.as_retriever() # -> 'sentence-transformers/all-MiniLM-L6-v2' [Donnees] -> Correspondance avec la base vectoriel\n",
    ") \n",
    "chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99640b7-542a-47fd-abe2-fb7e058ff215",
   "metadata": {},
   "source": [
    "##### Invoking Retrieval Question-Answering Chain\n",
    "\n",
    "In the code snippet below, the Retrieval Question-Answering chain (`chain`) is invoked with a specific query. The result is stored in the variable `result`, and the generated answer is accessed using `result['result']`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b51fb5d-217d-46ec-9633-c350ec651672",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Who is Tony?\\nWho is Laurent?',\n",
       " 'result': \" Laurent Grangeau is a Cloud Solution Architect at Sogeti Labs and a Cloud Architect at Finaxys. He is a member of CapGemini's Expert Connect program and is a member of the Cloud Services Expert Connect community. He has been working in the cloud for over 10 years and is passionate about new technologies. He holds certifications from Hashicorp and VMware and has a background in infrastructure and on-prem applications. Tony is also an advocate for the use of Serverless frameworks on AWS, and has spoken at various Meetup events on the topic.\",\n",
       " 'source_documents': [Document(page_content=\"Contact\\n+33698600201 (Mobile) laurent.grangeau@gmail.com\\nwww.linkedin.com/in/ laurentgrangeau (LinkedIn) www.laurentgrangeau.fr (Personal)\\nTop Skills\\nPublic Cloud\\nIndependence\\nDevOps\\nLanguages\\nFrancais (Native or Bilingual)\\nAnglais (Native or Bilingual)\\nEspagnol (Elementary)\\nCertifications\\nMCP 70-536 - TS: Microsoft .NET Framework - Application Development Foundation\\nCertification Architecte SI\\nMCTS 70-562 - TS: Microsoft .NET Framework 3.5, ASP.NET Application Development\\nM101P, MongoDB for Developers\\nMCTS 70-516 - TS: Accessing Data with Microsoft .NET Framework 4\\nHonors-Awards\\nFinaliste Hackathon DSI\\nMicrosoft MVP Azure - 2018\\nLaurent Grangeau\\nSolutions Architect at Google Paris et périphérie\\nSummary\\nJ'accompagne nos clients dans leur transformation numérique. Je\\nles aide à gagner en productivité, réduire leur time-to-market, ainsi\\nque leur coût d'infrastructure en développant leur stratégie cloud\\nExperience\", metadata={'source': 'docs/Profile Linkedin Laurent.pdf'}),\n",
       "  Document(page_content='Contact\\n0134490643 (Work) tjarriault@free.fr\\nwww.linkedin.com/in/tonyjarriault (LinkedIn)\\nTop Skills\\nSecurity\\nITIL\\nLinux\\nLanguages\\nEnglish\\nCertifications\\nHashiCorp Certified: Vault Associate\\nHashicorp terraform\\nProfessional Cloud Security Engineer\\nJarriault Tony\\nSolutions Architect @Sogeti part of CapGemini Greater Toulouse Metropolitan Area\\nSummary\\n☁ Cloud solution architect with a passion for new technologies. I\\nhave been immersed in the cloud for over 10 years :)\\n☑️I also have significant experience in infrastructure and onprem\\napplications\\n☑️TechLead GCP, I help teams and customers in the adoption of\\nthe cloud to help them pursue an exciting adventure around topics\\nsuch as: Finops / DevSecops / Micro-Service ...\\nSpeaker on public event, i share my passion about cloud technology\\nFavourite topics : ️AWS / ️GCP / ️Finops / ️DevSecOps / ️Cloud\\nExperience\\nSogeti Cloud Solutions Architect January 2019 - Present (5 years) Toulouse Area, France\\nPROSODIE 23 years 11 months', metadata={'source': 'docs/Profile Linkedin Tony.pdf'}),\n",
       "  Document(page_content=\"Meetup #3 : Avantages / Cas d'usage du Serverless - Le projet opensource\\nOpenWhisk\\nMeetup #2 : Serverless frameworks on AWS\\nMeetup #1 : Azure Functions, exécution de nano-services en mode serverless\\nSpeaker Speaker February 2013 - Present (11 years)\\n2017 : Skynet vs Planet of the Apes - DockerCon EU\\n2017 : Skynet vs Planet of the Apes - Breizhcamp\\n2017 : Skynet vs Planet of the Apes - Voxxed day Luxembourg\\n2017 : Skynet vs Planet of the Apes - Devoxx\\n2017 : All you need is orchestration ! - Snowcamp.io\\n2016 : Containers orchestration : an overview of Swarm, Mesos, Kubernetes\\nand Nomad - API Days\\n2016 : Globak Mentor Week - Meetup Docker\\n2016 : Making a mammoth run : continuous delivery in a bank - DevOpsDDay\\n2016 : Docker Windows + Continuous Delivery = <3 - Microsoft Experiences\\n2016 : Docker Windows + Continuous Delivery = <3 - Meetup Docker\\n2016 : Making a mammoth run : continuous delivery in a bank - HashiConf EU\\n2015 : The missing piece : when Docker networking unleashes software\", metadata={'source': 'docs/Profile Linkedin Laurent.pdf'}),\n",
       "  Document(page_content=\"architecture 2.0 - DockerCon EU\\n2015 : Networking with Docker - Pioneers.io\\n2013 : BI analysis with SQL Server 2012 - Microsoft TechDays\\nSogeti 4 years 6 months\\nTechnical Partner Manager January 2021 - November 2021 (11 months) Paris et périphérie\\nCloud Solution Architect | Business Developer June 2017 - January 2021 (3 years 8 months) Issy les moulineaux\\nSogetiLabs fellow : http://labs.sogeti.com/experts/laurent-grangeau/\\nMember of CapGemini Expert Connect program : https://www.capgemini.com/\\nexperts/cloud-services/laurent-grangeau/\\nPage 2 of 5\\nFINAXYS 2 years 5 months\\nCloud solution Architect | Consultant manager January 2017 - June 2017 (6 months)\\nMigration du SI de Kepler Cheuvreux vers le cloud AWS : Chiffrage du TCO,\\nDéfinition de leur nouvelle architecture, Mise en place de best practices.\\nResponsable de l'offre Cloud : Participation aux avant-ventes, Définition de\\nl'architecture Cloud de nos clients.\", metadata={'source': 'docs/Profile Linkedin Laurent.pdf'})]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chain.invoke(query)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d1c364-8fdb-4028-864c-8aa1a2c3affe",
   "metadata": {},
   "source": [
    "The result schema obtained from the Retrieval Question-Answering Chain consists of three main components: `query`, `result`, and `source_documents`. Here's a breakdown of each:\n",
    "\n",
    "1. `query`:\n",
    "    - Type: String\n",
    "    - Description: Represents the original query provided to the Retrieval Question-Answering Chain.\n",
    "2. `result`:\n",
    "    - Type: String\n",
    "    - Description: Contains the generated answer or response to the query. In this specific result, it provides information related to the academic and professional background of the individual, including education, work experience, and current role.\n",
    "3. `source_documents`:\n",
    "    - Type: List of Documents\n",
    "    - Description: Contains a list of documents (`Document` objects) that contributed to the generation of the answer. Each `Document` includes:\n",
    "        1. `page_content`: The content of the document.\n",
    "        2. `metadata`: Additional metadata associated with the document, in this case, the 'source' field specifying the document source file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eef8c3ed-ac0a-4621-aee3-c45fdb985a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Laurent Grangeau is a Cloud Solution Architect at Sogeti Labs and a Cloud Architect at Finaxys. He is a member of CapGemini's Expert Connect program and is a member of the Cloud Services Expert Connect community. He has been working in the cloud for over 10 years and is passionate about new technologies. He holds certifications from Hashicorp and VMware and has a background in infrastructure and on-prem applications. Tony is also an advocate for the use of Serverless frameworks on AWS, and has spoken at various Meetup events on the topic.\n"
     ]
    }
   ],
   "source": [
    "print(result['result'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277ea678-5afc-4cc9-b7c3-44c2824ebf01",
   "metadata": {},
   "source": [
    "##### Accessing Source Documents in the Result\n",
    "\n",
    "The following code snippet iterates over the source documents present in the result obtained from the Retrieval Question-Answering chain. The metadata information, specifically the `source` field, is extracted and printed for each source document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "785612a7-c3ad-455f-b56c-a7b56271fa4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs/Profile Linkedin Laurent.pdf\n",
      "docs/Profile Linkedin Tony.pdf\n",
      "docs/Profile Linkedin Laurent.pdf\n",
      "docs/Profile Linkedin Laurent.pdf\n"
     ]
    }
   ],
   "source": [
    "for source in result['source_documents']:\n",
    "    print(source.metadata['source'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bd47a3-63fc-44c3-b80a-8ee467f1bbc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Chatbot mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16332df9-533d-40a5-8174-0c20f6c7a124",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[exit|quit] pour sortir\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = True\n",
    "\n",
    "while True:\n",
    "    \n",
    "    if X:\n",
    "        print(\"[exit|quit] pour sortir\")\n",
    "        print()\n",
    "        X = False\n",
    "        \n",
    "    # Take user input\n",
    "    user_input = input(\">> \")\n",
    "\n",
    "    # Check if the user wants to quit\n",
    "    if user_input.lower() in [\"quit\", \"exit\"]:\n",
    "        print(\"Exiting the conversation.\")\n",
    "        break\n",
    "    \n",
    "    result = chain.invoke(user_input)\n",
    "    \n",
    "    print(f\"\\t<<{result['result']}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"<< sources:\")\n",
    "    for source in result['source_documents']:\n",
    "        print(f\"\\t<< {source.metadata['source']}\")\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd52c16-68a4-4274-afda-f7fc1a738a3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "[exit|quit] pour sortir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d60d4b4-6a70-4669-afd7-be5c64f8bef3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef64e88-8f1a-4d85-8dd8-8a581f8864b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Save the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "91d928d2-a84e-4315-bf41-f744163f9451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the RetrievalQA instance to a file\n",
    "with open('saved_chain.pkl', 'wb') as file:\n",
    "    pickle.dump(chain, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dde80e1-00c3-431e-8239-42fd4597b72d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Launch the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7cb68b45-4bd2-4690-b0d3-dc8dfd8ff678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python app.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c406b0b-e71d-4691-aff7-015f6ab3fcff",
   "metadata": {},
   "source": [
    "#### POST request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17788697-ebc8-4291-ab5a-cab72b993362",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"result\": \" Laurent Grangeau is a Solutions Architect at Sogeti Paris and Peripheries. He has extensive experience in Cloud Solution Architect and has worked on various projects such as Migration from SI of Kepler-Cheuvreux to AWS, Development of custom applications for the Financial sector, Migration of legacy infrastructure and Cloud migration. He is certified in Hashicorp Vault Associate for Hashicorp Terraform and has participated in the design and delivery of IT projects for his clients. Laurent is passionate about cloud technologies, especially AWS and GCP. He is a regular speaker at industry events and has been featured in the media.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST -H \"Content-Type: application/json\" -d '{\"query\": \"Tell me more about Laurent\"}' http://127.0.0.1:5001/api/search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4397957c-2fbf-427e-8ad0-3cf4bce1470a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"result\": \" Tony Jarriault\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST -H \"Content-Type: application/json\" -d \"{\\\"query\\\": \\\"What is the last name of Tony?\\\"}\" http://10.128.15.193:5001/api/search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2037cf20-bfa1-495a-a811-6b211e080de2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"result\": \" The Tony phone number at Capgemini is 0134490643 (Work)\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST -H \"Content-Type: application/json\" -d \"{\\\"query\\\": \\\"What is the Tony phone number at Capgemini ?\\\"}\" http://10.128.15.193:5001/api/search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6529b91e-3028-4e86-9b5a-e8143d91cede",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96b8c5a-ee4b-44f8-ac89-72c4c88a5e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d97cd74-1a2f-42a6-a837-0e159d6aab33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /opt/conda/lib/python3.10/site-packages (1.29.0)\n",
      "Requirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (1.7.1)\n",
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.1.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.2.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.7.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.3.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.11.0)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.25.2)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in /opt/conda/lib/python3.10/site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.0.3)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (10.1.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=6.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (14.0.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (13.7.0)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.2.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.9.0)\n",
      "Requirement already satisfied: tzlocal<6,>=1.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.2)\n",
      "Requirement already satisfied: validators<1,>=0.2 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.22.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.1.40)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.3.3)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.10.13)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.9 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.10)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.8)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.77 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.77)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.20.0)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (1.26.18)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.17.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.11.2)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.32.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.13.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit openai langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa55b806-efb4-4b80-ba40-43f2282b968f",
   "metadata": {},
   "source": [
    "# Start streamlit (frontend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824c503-f1ab-42e0-8a13-166305539cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.128.15.193:8502\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.225.189.176:8502\u001b[0m\n",
      "\u001b[0m\n",
      "/opt/conda/lib/python3.10/site-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
      "\n",
      "`from langchain_community.llms import OpenAI`.\n",
      "\n",
      "To install langchain-community run `pip install -U langchain-community`.\n",
      "  warnings.warn(\n",
      " Tony has 10 years of immersion in the cloud and has experience in infrastructure and onprem applications. He has also been involved in the cloud since 2012, which includes AWS and on-prem applications. Tony is passionate about cloud technology and shares his passion by sharing his knowledge on public events. Tony is also an experienced Sogeti Cloud Solutions Architect. He has experience with AWS, as well as DevSecops and micro-services in on-prem applications.\n"
     ]
    }
   ],
   "source": [
    "!cd streamlit\n",
    "!streamlit run streamlit/streamlit_app.py --server.port 8502"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18453c0-8243-4a51-a297-488dcffb12b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m114"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
